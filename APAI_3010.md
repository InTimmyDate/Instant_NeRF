# Setup
Firstly setup NeRF according to original paper readme

# Reproduction

We followed original paper readme

# Changes for the Project

We did not vary the source code of Instant NeRF significantly as previous attempts to do so have not yielded any ideal results.

## New Data

However, we included many new data sets stored in train data including data from the original NeRF paper `drums` `hotdog` `Lego` and `ship`,
and one variation after processed by u2net `lego_u2net`, as well as self-captured image data `chanel` and its smaller size versions, last but not least
a self-captured video data from class `Justin`

# Preparing new data set

## Preparing new NeRF datasets

To train on self-captured data, one has to process the data into an existing format supported by __instant-ngp__. We provide scripts to support three approaches:
- [COLMAP](#COLMAP) to create a dataset from a set of photos or a video you took
- [Record3D](#Record3D) to create a dataset with an iPhone 12 Pro or newer (based on ARKit)
- [NeRFCapture](#NeRFCapture) to create a dataset or stream posed images directly to __instant-ngp__ with an iOS device.

All require [Python](https://www.python.org/) 3.7 or higher to be installed and available in your PATH.

On Windows you can [download an installer from here](https://www.python.org/downloads/). During installation, make sure to check "add python.exe to PATH".

If you are using Debian based Linux distribution, install Python with
```sh
sudo apt-get install python3-dev python3-pip
```

Alternatively, if you are using Arch or Arch derivatives, install Python with
```sh
sudo pacman -S python python-pip
```

For all operating systems, after having installed Python, you need to install the required Python packages by opening a Windows Command Prompt / Linux terminal and calling
```sh
pip install -r requirements.txt
```

### COLMAP

If you use Linux, make sure that you have installed [COLMAP](https://colmap.github.io/) and that it is available in your PATH. If you are using a video file as input, also be sure to install [FFmpeg](https://www.ffmpeg.org/) and make sure that it is available in your PATH.
To check that this is the case, from a terminal window, you should be able to run `colmap` and `ffmpeg -?` and see some help text from each.

If you use Windows, you do not need to install anything. COLMAP and FFmpeg will be downloaded automatically when running the following scripts.

If you are training from a video file, run the [scripts/colmap2nerf.py](/scripts/colmap2nerf.py) script from the folder containing the video, with the following recommended parameters:

```sh
data-folder$ python [path-to-instant-ngp]/scripts/colmap2nerf.py --video_in <filename of video> --video_fps 2 --run_colmap --aabb_scale 32
```

The above assumes a single video file as input, which then has frames extracted at the specified framerate (2). It is recommended to choose a frame rate that leads to around 50-150 images. So for a one minute video, `--video_fps 2` is ideal.

For training from images, place them in a subfolder called `images` and then use suitable options such as the ones below:

```sh
data-folder$ python [path-to-instant-ngp]/scripts/colmap2nerf.py --colmap_matcher exhaustive --run_colmap --aabb_scale 32
```

The script will run (and install, if you use Windows) FFmpeg and COLMAP as needed, followed by a conversion step to the required `transforms.json` format, which will be written in the current directory. 

# To run the training process

Double click to open `instant-ngp` then simply drag the dataset intended to train into the interface and wait for the training process to start.
